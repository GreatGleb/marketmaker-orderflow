import json
import os
import time
from datetime import timezone, datetime, timedelta
from decimal import Decimal
import pandas as pd
import numpy as np

from sqlalchemy import select, func, text

from app.bots.binance_bot import BinanceBot
from app.crud.asset_history import AssetHistoryCrud
from app.crud.exchange_pair_spec import AssetExchangeSpecCrud
from app.db.base import DatabaseSessionManager
from app.crud.test_bot import TestBotCrud
from app.config import settings
import asyncio

from app.dependencies import redis_context
from app.workers.profitable_bot_updater import ProfitableBotUpdaterCommand

async def run():
    # await select_volatile_pair()
    await select_volatile_pair_from_file()

    return 0
    dsm = DatabaseSessionManager.create(settings.DB_URL)
    async with dsm.get_session() as session:
        shared_data = {}
        asset_crud = AssetHistoryCrud(session)
        exchange_crud = AssetExchangeSpecCrud(session)
        symbols = await asset_crud.get_all_active_pairs()

        for symbol in symbols:
            step_sizes = await exchange_crud.get_step_size_by_symbol(
                symbol
            )
            shared_data[symbol] = {
                "tick_size": (
                    Decimal(str(step_sizes.get("tick_size")))
                    if step_sizes
                    else None
                )
            }

    return 0
    #
    #     time_ago = timedelta(minutes=float(tf))
    #
    #     profits_data = await bot_crud.get_sorted_by_profit(
    #         since=time_ago, just_not_copy_bots=True
    #     )
    #     filtered_sorted = sorted(
    #         [item for item in profits_data if item[1] > 0],
    #         key=lambda x: x[1],
    #         reverse=True,
    #     )
    #     ids_tf = [item[0] for item in filtered_sorted]
    #
    #     time_ago_24h = timedelta(hours=float(24))
    #
    #     profits_data_24h = await bot_crud.get_sorted_by_profit(
    #         since=time_ago_24h, just_not_copy_bots=True
    #     )
    #     filtered_sorted_24h = sorted(
    #         [item for item in profits_data_24h if item[1] > 0],
    #         key=lambda x: x[1],
    #         reverse=True,
    #     )
    #
    #     ids_24h = [item[0] for item in filtered_sorted_24h]
    #     ids_checked_24h = [item for item in ids_tf if item in ids_24h]
    #
    #     profits_data_by_referral = await bot_crud.get_sorted_by_profit(
    #         since=time_ago_24h, just_not_copy_bots=True, by_referral_bot_id=True
    #     )
    #     filtered_sorted_by_referral = sorted(
    #         [item for item in profits_data_by_referral if item[1] > 0],
    #         key=lambda x: x[1],
    #         reverse=True,
    #     )
    #     tf_ids_by_referral = [item[0] for item in filtered_sorted_by_referral]
    #     ids_checked_by_referral = [item for item in ids_checked_24h if item in tf_ids_by_referral]
    #
    #     print(f'result: {len(ids_tf)}, result 24h: {len(ids_24h)}, result checked: {len(ids_checked_24h)}, tf_ids_by_referral: {len(tf_ids_by_referral)}, ids_checked_by_referral: {len(ids_checked_by_referral)}')
    #     for bot_id, total_profit, total_orders, successful_orders in [item for item in filtered_sorted_by_referral if item[0] in ids_checked_24h]:
    #         print(
    #             f"–ë–æ—Ç {bot_id} ‚Äî üí∞ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {total_profit:.4f}, "
    #             f"üìà –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ä–¥–µ—Ä–æ–≤: {successful_orders}/{total_orders}"
    #         )
    #     print(ids_checked_by_referral)
    #     for bot_id, total_profit, total_orders, successful_orders in [item for item in filtered_sorted if item[0] in ids_24h and item[0] in tf_ids_by_referral]:
    #         print(
    #             f"–ë–æ—Ç {bot_id} ‚Äî üí∞ –û–±—â–∞—è –ø—Ä–∏–±—ã–ª—å: {total_profit:.4f}, "
    #             f"üìà –£—Å–ø–µ—à–Ω—ã—Ö –æ—Ä–¥–µ—Ä–æ–≤: {successful_orders}/{total_orders}"
    #         )
    #
    # return
    #
    #
    #
    #
    # async with redis_context() as redis:
    #     binance_bot = BinanceBot(is_need_prod_for_data=True, redis=redis)
    #
    #     symbol = 'XRPUSDT'
    #     m = await binance_bot.get_ma(symbol, 25)
    #     double = await binance_bot.get_double_ma(symbol=symbol, less_ma_number=10, more_ma_number=25)
    #     history = await binance_bot.get_prev_minutes_ma(symbol=symbol, less_ma_number=10, more_ma_number=25, minutes=5)
    #
    #     print(f'm: {m}')
    #     print(f'double: {double}')
    #     print(f'history: {history}')


async def select_volatile_pair():
    dsm = DatabaseSessionManager.create(settings.DB_URL)
    async with dsm.get_session() as session:
        data = []
        exchange_crud = AssetExchangeSpecCrud(session)
        symbols = await exchange_crud.get_all_symbols()
        symbols = [symbol[0] for symbol in symbols]

        binance_bot = BinanceBot(is_need_prod_for_data=True)

        start_time = time.perf_counter()
        for symbol in symbols:
            fees = await binance_bot.fetch_fees_data(symbol)
            klines = await binance_bot.get_monthly_klines(symbol=symbol)
            if klines:
                vol_5min = calculate_volatility(klines, timeframe='5min')
                fees['vol_5min'] = vol_5min

                data.append(fees)
            await asyncio.sleep(3)

        end_time = time.perf_counter()
        execution_time = end_time - start_time

        print(f"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {execution_time} —Å–µ–∫—É–Ω–¥")

        print(len(symbols))
        print(vol_5min)
        print(data)

        current_directory = os.path.dirname(os.path.abspath(__file__))
        file_path = os.path.join(current_directory, 'most_volatile_asset.json')
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=4)

async def select_volatile_pair_from_file():
    current_directory = os.path.dirname(os.path.abspath(__file__))
    file_path = os.path.join(current_directory, 'most_volatile_asset.json')

    # –°–æ–∑–¥–∞—ë–º –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é, –≤ –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º —á–∏—Ç–∞—Ç—å –¥–∞–Ω–Ω—ã–µ
    read_data = None

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –ª–∏ —Ñ–∞–π–ª, —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –æ—à–∏–±–∫–∏
    if os.path.exists(file_path):
        # –û—Ç–∫—Ä—ã–≤–∞–µ–º —Ñ–∞–π–ª –¥–ª—è —á—Ç–µ–Ω–∏—è ('r' - read)
        with open(file_path, 'r', encoding='utf-8') as f:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ —Ñ–∞–π–ª–∞ –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é 'read_data'
            read_data = json.load(f)
        print("–î–∞–Ω–Ω—ã–µ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ—á–∏—Ç–∞–Ω—ã –∏–∑ —Ñ–∞–π–ª–∞!")

        # –¢–µ–ø–µ—Ä—å 'read_data' —Å–æ–¥–µ—Ä–∂–∏—Ç –º–∞—Å—Å–∏–≤/–æ–±—ä–µ–∫—Ç –∏–∑ —Ñ–∞–π–ª–∞
        print(read_data)
    else:
        print(f"–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {file_path}")


def calculate_volatility(klines, timeframe='5T', period=14):
    """
    –†–∞—Å—Å—á–∏—Ç—ã–≤–∞–µ—Ç —Å—Ä–µ–¥–Ω—é—é –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç—å (ATR) –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ.

    Args:
        klines (list): –°–ø–∏—Å–æ–∫ —Å–ø–∏—Å–∫–æ–≤ —Å–æ —Å–≤–µ—á–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏ (OHLC).
        timeframe (str): –¢–∞–π–º—Ñ—Ä–µ–π–º –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞ –≤–æ–ª–∞—Ç–∏–ª—å–Ω–æ—Å—Ç–∏.
                         –ü—Ä–∏–º–µ—Ä—ã: '1T' (1 –º–∏–Ω—É—Ç–∞), '5T' (5 –º–∏–Ω—É—Ç), '1H' (1 —á–∞—Å), '1D' (1 –¥–µ–Ω—å).
        period (int): –ü–µ—Ä–∏–æ–¥ –¥–ª—è —Å–≥–ª–∞–∂–∏–≤–∞–Ω–∏—è –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–∞ ATR. –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–µ –∑–Ω–∞—á–µ–Ω–∏–µ - 14.

    Returns:
        float: –û–¥–Ω–æ —á–∏—Å–ª–æ - —Å—Ä–µ–¥–Ω–µ–µ –∑–Ω–∞—á–µ–Ω–∏–µ ATR –∑–∞ –≤–µ—Å—å –ø–µ—Ä–∏–æ–¥ –Ω–∞ —É–∫–∞–∑–∞–Ω–Ω–æ–º —Ç–∞–π–º—Ñ—Ä–µ–π–º–µ.
               –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç None, –µ—Å–ª–∏ –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã.
    """
    if not klines:
        print("–û—à–∏–±–∫–∞: –°–ø–∏—Å–æ–∫ klines –ø—É—Å—Ç.")
        return None

    # --- –®–∞–≥ 1: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –∏ –æ—á–∏—Å—Ç–∫–∞ –¥–∞–Ω–Ω—ã—Ö ---
    try:
        # –°–æ–∑–¥–∞–µ–º DataFrame –∏–∑ "—Å—ã—Ä—ã—Ö" –¥–∞–Ω–Ω—ã—Ö
        df = pd.DataFrame(klines, columns=[
            'timestamp', 'open', 'high', 'low', 'close', 'volume',
            'close_time', 'quote_asset_volume', 'number_of_trades',
            'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'
        ])

        # –í—ã–±–∏—Ä–∞–µ–º —Ç–æ–ª—å–∫–æ –Ω—É–∂–Ω—ã–µ –∫–æ–ª–æ–Ω–∫–∏ –∏ —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ —Ç–∏–ø—ã –¥–∞–Ω–Ω—ã—Ö
        df = df[['timestamp', 'open', 'high', 'low', 'close']]
        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')
        df.set_index('timestamp', inplace=True)
        for col in ['open', 'high', 'low', 'close']:
            df[col] = df[col].astype(float)

    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏—Å—Ö–æ–¥–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
        return None

    # --- –®–∞–≥ 2: –ü—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ (resampling) –≤ –Ω—É–∂–Ω—ã–π —Ç–∞–π–º—Ñ—Ä–µ–π–º ---
    aggregation_rules = {
        'open': 'first',
        'high': 'max',
        'low': 'min',
        'close': 'last'
    }
    df_resampled = df.resample(timeframe).agg(aggregation_rules)
    df_resampled.dropna(inplace=True)  # –£–¥–∞–ª—è–µ–º –∏–Ω—Ç–µ—Ä–≤–∞–ª—ã –±–µ–∑ –¥–∞–Ω–Ω—ã—Ö

    if df_resampled.empty:
        print(f"–û—à–∏–±–∫–∞: –ü–æ—Å–ª–µ –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –≤ —Ç–∞–π–º—Ñ—Ä–µ–π–º '{timeframe}' –Ω–µ –æ—Å—Ç–∞–ª–æ—Å—å –¥–∞–Ω–Ω—ã—Ö.")
        return None

    # --- –®–∞–≥ 3: –†–∞—Å—á–µ—Ç ATR –¥–ª—è –Ω–æ–≤–æ–≥–æ —Ç–∞–π–º—Ñ—Ä–µ–π–º–∞ ---
    high_low = df_resampled['high'] - df_resampled['low']
    high_prev_close = abs(df_resampled['high'] - df_resampled['close'].shift(1))
    low_prev_close = abs(df_resampled['low'] - df_resampled['close'].shift(1))

    true_range = pd.concat([high_low, high_prev_close, low_prev_close], axis=1).max(axis=1)

    df_resampled['atr'] = true_range.ewm(alpha=1 / period, adjust=False).mean()
    df_resampled['atr_percent'] = (df_resampled['atr'] / df_resampled['close']) * 100

    # --- –®–∞–≥ 4: –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∏ –≤–æ–∑–≤—Ä–∞—Ç –∏—Ç–æ–≥–æ–≤–æ–≥–æ —Å—Ä–µ–¥–Ω–µ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è ---
    # np.nanmean —Å—á–∏—Ç–∞–µ—Ç —Å—Ä–µ–¥–Ω–µ–µ, –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∏–≥–Ω–æ—Ä–∏—Ä—É—è –Ω–∞—á–∞–ª—å–Ω—ã–µ –ø—É—Å—Ç—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è ATR
    average_volatility = np.nanmean(df_resampled['atr_percent'])

    return average_volatility



if __name__ == "__main__":
    asyncio.run(run())
